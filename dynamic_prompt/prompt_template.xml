<root>
    <overview>
        - I'd like to be able to run llm prompts, which get fed my current clipboard selection as an input from anywhere on my mac.
        - In order to do so I have already built a simplified version of it, an automator app which runs #variables.shell_script 
        - It uses the current clipboard selection as the entire input to the llm.
        - The next step in building this workflow is to extend it, such that the clipboard selection is no longer the entire prompt, but gets inserted into a prompt template like #variables.prompt_template
        - This should be done using a script like #variables.dynamic_prompt_building.py
    </overview>

    <variables>
        <shell_script>
            """bash
            {{file:ollama_shell_script.sh}}
            """
        </shell_script>

        <dynamic_prompt_building>
            """python
            {{file:dynamic_prompt_building.py}}
            """
        </dynamic_prompt_building>

        <prompt_template>
            """xml
            {{file:prompt_template.xml}}
            """
        </prompt_template>
    </variables>

    <question>
        - What is the most convenient way to achieve my goal?
    </question>
</root>